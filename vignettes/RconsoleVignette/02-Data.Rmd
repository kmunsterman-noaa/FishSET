# Data

## Required and optional data

FishSET uses five data types. 

```{r table1, echo=FALSE, message=FALSE, warnings=FALSE, results='asis'}
tabl <- "  

| File Type        | Description                                                         |
|------------------|---------------------------------------------------------------------|
| Primary data     | Required. Contains the main data for the model.                     |
| Port data        | Required. Contains latitude and longitude locations of ports.       |
| Spatial data     | Required. File defining boundaries of fishery or regulatory zones.  |
| Gridded data     | Optional. Contains additional data that varies by two dimensions.   |
|                  |     Example, sea surface temperature measure                        |
| Auxiliary data   | Optional. Contains additional data to link to the primary data.     |
|                  |     Example, vessel characteristics.                                |
"
cat(tabl) # output the table in a format good for HTML/PDF/docx conversion
```

All optional data files must be linkable to the primary data file.

Gridded data should link to the fishery or regulatory areas in the spatial data. Auxilary data must link to a variable in the primary data table.

FishSET will accept several data formats including:

  * csv files
  * geojson files
  * json files
  * matlab files
  * R files  
  * shape files
  * spss files
  * stata files
  * txt files
  * xls/xlsx files
  
  Details on the different data types are detailed in the [Data Types](https://docs.google.com/document/d/1dzXsVt5iWcAQooDDXRJ3XyMoqnSmpZOqirU_f_PnQUM/edit#heading=h.36sb14g0441y) section of the FishSET manual.

## Loading and reading data

### Loading data to the FishSET database
All data should be saved to the FishSET database. Doing so ensures that data for a project are stored together. 

The *load* functions check that the data file can be saved to the FishSET database and, if all checks pass, saves the data file to the FishSET database.

When the primary data is saved, two versions of the data are created, a raw table with the original data and a working table on which all analyses will be conducted. The working table will also be available in the global environment. Revised data can be saved as interim tables in the database along with a "finalized" data table (data table used for models).

#### Functions
  
     load_maindata() Primary data file. 
     load_port()     Port data file. 
     load_aux ()     Auxiliary data file. 
     load_grid()     Gridded data file.

#### Function details
`load_maindata(dat, project, over_write = TRUE, compare = FALSE, y = NULL)` read in a data file, then parses it, and finallys saves the data table to the FishSET database if no errors are found. The function calls the `data_verification` function to check for common data quality issues and that latitude and longitude are defined in `dat`. If no issues are found, the data is saved in the FishSET database for the `project` as `projectMainDataTable` and loaded into the working environment. If `over_write =TRUE`, the existing data table for the project, if exists in the FishSET database, will be overwritten. If `compare = TRUE` the `fishset_compare` function is called and `dat` is compared with `y`, a previously saved version of `dat`.
 
`load_port`

`load_spatial`

`load_aux`

`load_grid`

>"Add details about loading port, spatial , auxiliary, and gridded files."


### Reading data into R
Data can also be read into R without saving it to the FishSET database. This function should only be used to view and evaluate data tables. If the data is going to be used in FishSET it should be loaded into the FishSET database.

To read data files into the working environment use: 

     read_dat(x, data.type = NULL, is.map = F, ...). 


#### Function details
`read_dat(x, data.type=NULL, is.map = FALSE, drv = NULL, dbname = NULL, user = NULL, password = NULL, ...)` import data from local file directory or webpage into the R environment. `x`is the name and path, or web address, of the dataset to be read in. `data.type` is the file extension. It is optional as the function will attempt to detect the file extension. `data.type` must be defined if `x` is the path to a shape folder, if `x` is a Google spreadsheet (`data.type = 'google')`, or if the correct extension cannot be derived from `x`. Set `is.map = TRUE` only for spatial files in a .json file extension. For sql files, additional arguments may be required, including the database driver (`drv`), the database name (`dbname`), and user name (`user`) and password (`password`) for the SQL database. 
  
`read_dat()` is flexible and will accommodate several data extensions and additional format-specific arguments. It is a wrapper function that calls a file extension-specific function to read in the data. `x` is the name and path of the dataset to be read in. `data.type` is optional argument to specify the file extension. If `data.type` is not specified, the detected data extension in `x` will be used. `is.map` is a logical argument specifying if `x` is a spatial data file. is.map must be set to TRUE if a spatial data file is not in a geojson or shape file. `...` is used to add additional extension-specific arguments. See function documentation for more details.  


### Loading data from FishSET database into the the working environment
Data saved to the FishSET database can be reloaded into the working environment using 

     load_data(project, name=NULL). 

Specify the project name (`project`) and, optionally, the table name (`name`). `name` is optional and is used to specify a specific  version of the data table.  For example,

     load_data("pollock", name="pollockMainDataTable20200101")   

loads the primary data from project *pollock* that was saved on January 1st, 2020. If `name` is NULL, the undated working table is pulled.

```{r eval=FALSE, echo=TRUE}
##Load in the data from the pollock project
library(FishSET)
load_data("pollock")
```

## Merging gridded and auxiliary data with the primary data
Secondary data (auxiliary, port, gridded) can be merged into the primary dataset. The default method to merge is to use a left join; all columns and rows from the primary dataset are kept whereas only matching columns and rows from the secondary table are joined. Although all secondary data types can be merged into the primary day, generally only auxiliary data (such as vessel characteristics) will need to be merged.


#### Functions

    merge_dat()   Merge secondary data into the primary data tahble
    split_dat()   Split and save secondary data from the primary data table


#### Function details
`merge_dat(dat, other, project, main_key, other_key, other_type = NULL, merge_type = "left")` merges secondary data (`other`) to the primary data (`dat`) based on one or more variables for `dat` (`main_key`) and `other` (`other_key`). If more than one variable is being used for merging, include as a list. Variable names do not have to be the same between `main_key` and `other_key` but they must be included in the same order. `other_type` is optional and defines the data type of the secondary data (“aux”, “grid”, “spat”, “port”).  `merge_type` can be “left” or “full”. “left” keeps all columns and rows in `dat` but only the rows from `other` in which the column values match column values in `dat`. “full” keeps all rows of both `dat` and `other.` “left” merge is preferred as using “full” can result in a larger frequency of missing data if the secondary data contains observations beyond the scope of `dat`. For example, `dat` contains catch data only on catcher vessels but other contains vessel characteristics for catcher vessels, mothership vessels, and catch processor vessels.

`split_dat(dat, aux = NULL, project, split_by = NULL, key, output = "main")` separates secondary data (auxiliary, gridded, or port data) from the MainDatatable. Identify data to remove from `dat` using an existing secondary data table or list of column names. If `aux` is specified, the column names in `dat` that match the column names in `aux` are separated from `dat`. If `aux = NULL` and `split_by` is a list, then column names in `dat` matching `split_by` are separated from `dat`. `key` is the columns that link `dat` and `aux.` If `aux` is null then `key` should be a column name from `split_by`. The function can return just the primary data (`output = “main”`), just the separated table (`output = “aux”`), or both, in a list (`output = “both”`).


## Working in the FishSET database  
The functions in this section interface with the FishSET database to display the requested output in the R Console. The functions are wrappers for functions in the **DBI** package. They allow users to focus on the data and not on managing the database or learning SQL.


Basic functions:
 
     tables_database(project)        View list of all tables in the FishSET database for the project.
     list_MainDataTables(project)	   View list of MainDataTables in FishSET database for the project.
     list_PortTables(project)	       View list of PortTables in FishSET database for the project.
     list_logs(project)		           View list of all log files for the project.
     table_fields(table, project)    View fields in specified table for the project.
     table_view(table, project)      Display specified table for the project.
     table_exists(table, project)	   Check if table exists in the FishSET database for the project.
     table_remove(table, project)	   Remove table from the FishSET database for the project.

     
 Model output files can be viewed in the FishSET database using:
     
     globalcheck_view(table, project)  View error output discrete choice models for the project
     model_out_view(project)    Load discrete choice model output for the project
 
## Metadata 
>"This needs to be detailed"

## Data management functions
Data should, at a minimum, be checked for entry errors and errors resulting from data import and conversion. Users should also investigate and summarize the data to understand potential data and statistical problems.

FishSET provides a number of statistical and graphic functions for evaluating data quality. These functions focus on issues that are most likely to affect model convergence and model performance. They do not cover all potential data quality issues that exist in your data. 

### Functions

#### Visualizing the data 
  
     summary_stats()    Table with basic summary statistics.
     spatial_hist()     Histogram of lat and lon by grouping variable.
     spatial_summary()  Line plots of selected variable against date and zone.
     map_plot()         Static map of haul locations.

####  Subsetting the data
  
     select_vars()      Select variables to add back into the working dataset. 
     add_vars()         Add variables from `select_vars` into primary dataset.

####  Checking for outliers  
  
`outlier_boxplot(dat, project, x = NULL)` returns a box-and-whisker plot of all numeric variables in `dat`. Use `x` to define a set of variables to assess. This function helps to identify which variables potentially contain outlier variables and should be run before outlier_table() and outlier_plot() functions, which can be applied to only one variable at a time.

     outlier_table()    Returns table with quantiles for all numeric variables in the data table.
     outlier_plot()     Returns a plot of the selected variable.
     outlier_remove()   Returns modified data set where outliers have been removed.
 
####  Checking for empty variables, unique rows, NAs, and NaNs 
  
     empty_vars         checks for emtpy variables.
     nan_identify()     Checks whether NAs or NaNs are present in any variable.
     nan_filter()       Returns modified data set where NaNs have been removed or replaced.
     na_filter()        Returns modified data set where NAs have been removed or replaced.
     unique_filter()    Check for and remove duplicate rows.
 
####  Filtering rows of the dataset
  
     filter_table()     Stores filter functions in a table.     
     filter_dat()       Apply stored and new filter functions to data.
 
####   Converting class or lon/lat units
     
     change_class()       Convert variable class.
     degree()            Convert lon/lat to decimal format.

####  Wrappers for multiple "checking" functions
  
     data_check()        Wrapper for data quality check functions, including data_verification().
     data_verification() Checks for unique column names, each row is a unique choice occurrence, etc.
     check_model_data()  Checks for presence of NAs, NaNs and Inf in model data. Function must be run before models can be developed.

  
### Function details 
#### Visualizing the data 
  
`summary_stats(dat, project, x = NULL)` prints summary statistics for each variable in the `dat`. If `x` is specified, summary stats will be returned only for that variable. 
   
     spatial_hist()    
     spatial_summary()  
     map_plot()         

####  Subsetting the data
  
     select_vars()       
     add_vars()         

####  Checking for outliers  
  
     outlier_boxplot
     outlier_table()    
     outlier_plot()     
     outlier_remove()   
 
####  Checking for empty variables, unique rows, NAs, and NaNs 
`empty_vars_filter(dat, project, remove = FALSE)` checks for empty variables and prints an outcome message to the console. If empty variables are present and `remove = TRUE`, then empty variables will be removed from `dat`.
  
     nan_identify()     
     nan_filter()  
     
`na_filter(dat, project, x=NULL, replace = F, remove = F, rep.value = NA, over_write = FALSE)` checks for NAs and removes or replaces NAs. To check for NAs across `dat`, run the function specifying only `dat` [`na_filter(pollockMainDataTable)`]. The function will return a statement of which variables, if any, contain NAs.  To remove NAs, use `remove = TRUE`. All rows containing NAs in variable(s) `x` will be removed from `dat`. To replace NAs, use `replace = TRUE`. If `replace = TRUE` and `rep.value` is not defined, then NAs are replaced with the mean value of `x`. `rep.value` must be specified if `x` is not numeric. The function returns the modified dataset if either `replace` or `remove` are true. Save the modified data table to the FishSET database by setting `over_write = TRUE`. 

`unique_filter(dat, project, remove = FALSE)` returns a statement of whether each row in `dat` is unique. Set `remove=TRUE` to remove duplicate rows.

####  Filtering rows of the dataset
  
     filter_table()      
     filter_dat()     
 
####   Converting variable class or lon/lat units

`change_class(dat, project, x = NULL, newclass = NULL, savedat = FALSE)` returns a table with data class for each variable in `dat` and changes variable classes. To view variable classes run the function with default settings, specifying only `dat` and `project`. If variable class should be changed, run the function again, specifying the variables (`x`) to be change and the newclasses (`newclass`). Length of `newclass` should match the length of `x` unless all variables in `x` should be the same class. Options are "numeric", "factor", "date", and "character". Use `savedat = TRUE` to save modified data table.

     
     degree()            

####  Wrappers for multiple "checking" functions
  
`data_check()` is the primary function to check for data quality issues in the dataset. The function calls `summary_stats`, `nan_identify`, `outlier_table` and `outlier_plot`, and `data_verification`, which contains script to check for unique column names and empty columns, that each row is a unique observation at haul or trip level, and calls the `degree` function. Use `outlier_remove`, `na_filter`, `nan_filter`, and `degree` to correct any errors. Empty columns and duplicate rows will be removed. 

`data_verification(dat, project)` checks that all column names in the `dat` are unique, whether any columns in the data frame are empty, whether each row is a unique choice occurrence at the haul or trip level, and that either latitude and longitude or fishing area are included.


```{r}
#data_check(pollockMainDataTable, 'pollock', 'OFFICIAL_TOTAL_CATH_MT')
```


`check_model_data` checks for data quality issues that will result in errors when running models, including NAs, NaNs and INF values in the dataset and that each row is a unique occurrence at the haul or trip level. Run this function before creating the model design file (`make_model_design`). Even if the data passed the `data_check` tests, errors may be produced by data modification and data creation functions.

Use `filter_table` and `filter_dat` to subset the data, retaining rows that meet the condition. Define and save, for records and future use, conditions in `filter_table`. Apply filters with `filter_dat`.

```{r table2, echo=FALSE, message=FALSE, warnings=FALSE, results='asis'}
tabl <- '   
| Data table      |   Vector       |  FilterFunction           |
|-----------------|----------------|---------------------------|
| MainDataTable   |  "PORT_CODE"   |  PORT_CODE == 1           |
| MainDataTable   |  "TRIP_START"  |  TRIP_START >= 2011-02-01 |
| PortDataTable   |  "LATITUDE"    |  LATITUDE < 57            |

'
cat(tabl) # output the table in a format good for HTML/PDF/docx conversion
```

