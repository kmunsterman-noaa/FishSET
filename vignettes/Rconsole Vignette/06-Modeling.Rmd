# Modeling Functions

## Modeling functions
Model development in FishSET requires preparing the data and defining model parameters. This section details the required and optional data, model choices, and model output evaluation functions.  

Generate necessary data	

    create_startingloc()        Starting location variable.         
    create_alternative_choice() Define alternative fishing choices.	  
    create_expections()         Define expected catch/revenue matrix.	
    
Check data
    
    check_model_data()          Check model data for possible issues with data.

Design model

    make_model_design()         Make model design.	                    
    discretefish_subroutine()   Run model.	                            

Assess model output	

    globalcheck_view()          Model error.
    model_out_view()            Model output.	
    Metrics	model_fit()         Model comparison.
    select_model()              Select best model.	


###Generate necessary data
All models require catch data, data on the chosen fishing location (choice), and a distance matrix.  Price data, location when choice of where to fish next, and expected catch matrices are required for some models. Additional optional data that interact with travel distance or vary by location may also be added. These data and the functions to generate them are outlined next.

**Distance matrix**  
This function returns the matrix of distances between observed and alternative fishing choices (where they could have fished but did not). The distance matrix is saved in the model design file in the FishSET database and pulled when the model run function is called. 

    create_alternative_choice(dat, project, alt_var, occasion, griddedDat, dist.unit, min.haul, gridfile, cat, lon.dat, lat.dat, hull.polygon, closest.pt, lon.grid, lat.grid, weight.var)

The distance matrix can be generated from the primary haul-level data (`dat`) or from gridded data (`griddedDat`) such as sea surface temperature. We describe generating the distance matrix from `dat` first. 

*From `dat`*  
Define how to find the longitude and latitude for the starting (`occasion`) and alternative (`alt_var`) locations. Choices are the centroid of the zone where the haul occurred (*“centroid”*), a port variable in `dat` (such as disembarked port), or paired latitude and longitude variables in `dat` such as haul starting location. Distance  can be returned in *"miles"*, *"kilometers"*, or *"meters"* (`dist.unit`). Remove zones with insufficient data by setting `min.haul` to the minimum number of hauls required.

If `alt_var` or `occasion` are *“centroid”* then the centroid of zones must be obtained. If a centroid table exists in the FishSET database and a zone identifier variables is in `dat`, then only `gridfile` needs to be defined. `gridfile` should the name of the gridfile, in quotes. For example, `gridfile = "gridname"`. If centroids or zone assignments must be calculated then `gridfile`, `cat`, `lon.dat`, and `lat.dat` must be specified. `hull.polygon`, `closest.pt`, `weight.var` are optional `lon.grid` and `lat.grid` must be defined if `gridfile` is a data frame. See `assignment_column()` for more details on optional arguments.

If `occasion` is a port variable, a port table containing the latitude and longitude of ports is required. If a port table does not exist in the FishSET database run the `load_port()` function before running `create_alternative_choice`.

If `alt_var` or `occasion` are paired longitude and latitude variables from `dat` then `alt_var` or `occasion` should be specified as *`c(lon, lat)`*.  
<br>
*From `griddedDat`*  
Alternatively, the distance matrix can be generated from a gridded dataset, such as sea surface temperature. In this case, only `dat`, `project`, and `griddedDat` must be specified. Columns in the gridded data file must be individual zones and must match the zone identifier variable in `dat`. The gridded data can vary over a second dimension, such as date, but must match a variable in `dat`. We recommend saving the gridded data file to the FishSET database using the `load_grid()` function.

**Expected catch matrix**  
This function returns the expected catch or revenue matrix for alternative fishing zones (zones they could have chosen but that the fisher did not in this choice opportunity). This matrix is required to run the conditional logit model that utilizes an average revenue specification. 

    create_expectations(dat, project, catch, price, defineGroup, temp.var, temporal, calc.method, lag.method, empty.catch, empty.expectation, temp.window, temp.lag, year.lag, dummy.exp, replace.output)

The `create_expectations()` function requires a catch variable. To return expected revenue, include a price or value variable from `dat`. `price` is multiplied against catch to generate revenue. If revenue exists in `dat` and you wish to use this revenue instead of price, then `catch` must be a vector of 1 of length equal to `dat`.

Expected catch/revenue can be calculated across the entire dataset (`defineGroup = “fleet”`) or within groups and across the entire record of catch (`temp.var = NULL`) or can take variation in catch over time into account. To take temporal patterns in catch into account, first identify the temporal variable (`temp.var`) in `dat` to use. Next, select whether to use a sequential (`temporal = "sequential"`) or daily timeline (`temporal = "daily"`). Sequential timeline sorts data by date but does not take into account that days may be missing. Daily timeline adds in these dates with NA (missing value). With sequential timeline, a window size of seven means catch would be the average over the past seven fishing days. Whereas, with daily timeline, it would be the average over seven calendar days. `year.lag` can be 0 (current year), 1 (previous year's data), or any other viable years to go back. Window size (`temp.window`) is in days and can be current day (0), a week (7), or any other numeric value. `temp.lag` is numeric and in days. For each day *x* in `temp.var`, catch is the average catch across *w* days (`temp.window`) starting *d* days (`temp.lag`) and *y* years (`year.lag`) before *x*. 

Using the specified moving window parameters, a matrix of average catch is created with *zone\*group* creating rows and *`date`* the columns. This is the standard average catch `(calc.method = “standardAverage”`). Alternatively, you can use the simple lag regression of the mean (`calc.method = “simpleLag”`) which calculates the predicted value for each zone`*`group and date given regression coefficients *p* for each zone`*`group. The lag method (`lag.method`), can use regression over entire group (*"simple"*) or for grouped time periods (*"grouped"*).

The expected catch matrix is pulled from the matrix of calculated catches for each date and zone. The matrix is of dimensions *(number of rows of dat)\*(number of alternatives)*. Expected catch is filled out by mapping the calculated catch for each zone given the observed date (if specified) and group (if specified) in `dat`. Note that empty catch values are considered to be times of no fishing activity and are not included. Values of 0 in the catch variable are considered times when fishing activity occurred but with no catch. These zero values are included in calculations. Sparsity in data should be considered when deciding how to take into account that catch may vary over time. Check for sparsity with the `temp_obs_table()` function. A broader window size or using the entire temporal record may be necessary. Empty catch values and empty expected catch values can be filled but only on a limited basis as doing so can lead to biased or misleading results. If there are a lot of empty values, consider changing the temporal arguments to reduce data sparsity. `empty.catch` can be *0*, the average of all catch values (*"allCatch"*") or the average of grouped catch values (*"groupedCatch"*). `empty.expectation` can be 0 or 1e-04. 

The function returns four expected catch or expected revenue matrices based on predefined window size and lags in days and years and all other user-defined arguments : 

    selected temporal arguments
    expected catch/revenue based the previous two days (short-term) catch,
    expected catch/revenue based the previous seven days (medium-term) catch,
    and expected catch/revenue based on the previous years (long-term) catch.

**Starting location**  
The starting location vector is required for the full information model with Dahl’s correction (`logit_correction`). The vector is the zone location of a vessel when the decision of where to fish next was made. Generally, the first zone of a trip is the departure port. Create the starting location vector before creating the model design file (`make_model_design()`). 

    create_startingloc(dat, gridfile, portTable, trip_id, haul_order, starting_port, lon.dat, lat.dat, cat, name = "startingloc", lon.grid, lat.grid)

The `create_startingloc()` function adds a starting location vector to the dataset (`dat`).

A zonal identifier variable is required. If zone identifier variable does not exist, the `assignment_column()` function is called to assign starting port locations and haul locations to zones and the following arguments are required: `gridfile`, `lon.dat`, `lat.dat`, `cat`, `lon.grid`, `lat.grid`. See `assignment_column` documentation for details. 

The first zone is generally the zone of the departure port. The table containing port latitude and longitudes (`portTable`) is required. This should be in the FishSET database. Also required is the variable in `dat` containing names of starting ports (`starting_port`). `trip_id` is a variable in `dat` containing unique trip identifiers. `haul_order` is a variable in `dat` containing the order of hauls within trips. 

**Additional optional data**  
`vars1` is a character string of additional *travel-distance* variables to include in the model, such as vessel characteristics. `vars2` is a character string of additional variables to include in the model, wind speed within zones. These depend on the likelihood. The details of the functions depend on the likelihood function and are outlined in the [FishSET Help Manual](LINK1!) and likelihood function documentation.

###Model choices
Model choices include the likelihood functions, optimization method, optimization options, and starting parameter values. These, along with the required and optional data are specified in the `model_design_function()`. The model design file is saved to the FishSET database and called by the `discretefish_subroutine()` function to run the models.

    make_model_design(dat, project, catchID, replace = TRUE, likelihood = NULL, initparams, optimOpt, methodname, mod.name, vars1 = NULL, vars2 = NULL, priceCol = NULL, startloc = NULL, polyn = NULL)

    discretefish_subroutine(project, select.model = FALSE)

The model design function requires the variable name in `dat` containing catch data. The distance and expected catch/revenue matrices do not have to be specified. They will be pulled based on `project` from the FishSET database. `startloc` is the name of the variable containing starting locations, if required. `priceCol` is optional argument to specify the variable in `dat` containing price data. It is required for the expected profit models (*epm_normal, epm_weibull, epm_lognormal*). `vars1` is a character string of optional *travel-distance* variables and `vars2` is a character string of optional *grid-varying* variables. These two arguments should be *NULL* if no additional data is being included. `polyn` is the correction polynomial degree. It is required for the *logit_correction* model.

FishSET allows only one model design file per project. Multiple models can be added to this file. Models are added on at a time using the `make_model_design()` function. Identify individual models with `model.name`. Models are added to the model design file by setting `replace = FALSE`. `replace = TRUE` will remove the existing model design file and only the currently specified model in `make_model_design()` will be in the model design file. 

The remaining arguments in `make_model_design()` are detailed below.

**Likelihood functions (`likelihood`)**

FishSET has six built-in likelihood functions. 

    Function	        Likelihood name	                                        Reference
    ________________________________________________________________________________________________
    logit_c	            Conditional logit likelihood	                          McFadden 1974
    logit_avgcat	    Average catch multinomial logit procedure	              Abbot and Wilen 2011
    logit_correction	Full information model with Dahl’s correction function	  Dahl 2002 
    epm_normal	        Expected profit model with normal catch function	      Haynie and Layton 2010
    epm_weibull	        Expected profit model with Weibull catch function	      Haynie and Layton 2010
    epm_lognormal	    Expected profit model with lognormal catch function	      Haynie and Layton 2010

See function documentation or the [Help Manual](LINK!!!) for more details.

**Initial parameter values (`initparams`)**

The number of initial parameter values and the order depend upon the specified likelihood function and the number of travel-distance and grid-varying variables included.

*logit_c*  
Starting parameter values take the order of `c[(alternative-specific parameters), (travel-distance parameters)]`. The length is the *number of alternative-specific variables* plus *number of travel-distance variables*.

*logit_avgcat*  
Starting parameter values take the order of: `c[(average-catch parameters), (travel-distance parameters)]`. The length is the *(number of average-catch variables)\*(k-1)* plus the *number of travel-distance variables*. `k` equals the number of alternative fishing choices.

*logit_correction*  
starting parameter order takes: `c[(marginal utility from catch), (catch-function parameters), (polynomial starting parameters), (travel-distance parameters), (catch sigma)]`. The marginal utility from catch and catch sigma are of length equal to unity respectively. The catch-function and travel-distance parameters are of length *(number of catch variables)\*(k)* and *number of cost variables* respectively. The number of polynomial interaction terms is currently set to 2, so given the chosen degree `polyn` there should be *(((polyn+1)\*2)+2)\*(k)* polynomial starting parameters, where `k` equals the number of alternative fishing choices. 

*epm_normal*  
Starting parameters values take the order of: `c[(catch-function parameters), (travel-distance parameters), (catch sigma(s)), (scale parameter)]`. The catch-function and travel-distance parameters are of length *(number of catch-function variables)\*(k)* and *(number of travel-distance variables)* respectively, where `k` equals the number of alternative fishing choices. The catch sigma(s) are either of length equal to unity or length `k` if estimating location-specific catch sigma parameters. The scale parameter is of length equal to unity.

*epm_weibull*  
Starting parameter values takes the order of: `c[(catch-function parameters), (travel-distance parameters), (catch sigma(s)), (scale parameter)]`. The catch-function and travel-distance parameters are of length *(number of catch-function variables)\*(k)* and *(number of travel-distance variables)* respectively, where `k` equals the number of alternative fishing choices. The catch sigma(s) are either of length equal to unity or length `k` if estimating location-specific catch sigma parameters. The scale parameter is of length equal to unity.

*epm_lognormal*  
Starting parameter values takes the order of: `c[(catch-function parameters), (travel-distance parameters), (catch sigma(s)), (scale parameter)]`.  The catch-function and travel-distance parameters are of length *(number of catch-function variables)\*(k)* and *(number of travel-distance variables)* respectively, where `k` equals the number of alternative fishing choices. The catch sigma(s) are either of length equal to unity or length `k` if estimating location-specific catch sigma parameters. The scale parameter is of length equal to unity.

Optimization options (`optimOpt`)

: Maximum number of iterations  
Relative convergence tolerance  
Report frequency  
Level of tracing information returned

As a guide, the optimization function `optim` in the **stats** package defaults to 100 for derivative-based methods, 500 for “Nelder-Mead” and 10000 for “SANN”. The relative tolerance should be very small. The default is 1e-08. Report frequency is the frequency of reports such as every 10 iterations for "BFGS" or every 100 temperatures for "SANN". Tracing must be 1 or higher for reports to be returned. Higher values return more details. 

**Optimization method (`methodname`)**  
Choices are “BFGS”, "L-BFGS-B", “Nelder-Mead”, “Brent”, “CG”, and “SANN”. Default is "BFGS".

**Running and saving models**
To run the defined models, use `discretefish_subroutine(project, select.model = FALSE)`. Each model can take 10 or more minutes to run.

It may be desirable to identify the “best” or preferred models for future reference. Identifying the “best” model can be done in the `discretefish_subroutine()` function by setting `select.model = TRUE` or using the `select_model(project, overwrite_table=FALSE)` function. Both produce a *modelChosen* table that is saved to the FishSET database. This table is not used in any functions.
R Console

In the R console, an interactive data table can be opened by setting select.model in discretefish_subroutine() to TRUE or with the select_model() function. 
`select_model()`
The interactive table contains the name of the model and model measures of fit for each model. Users can delete models from the table and select the preferred model by checking the selected box. The table is saved to the FishSET database with two new columns added, a TRUE/FALSE selected column and the date it was selected if overwrite_table is TRUE. The table is saved with the phrase 'modelChosen' in the FishSET database. 
FishSET GUI
Identifying and recording the “best” or preferred model is done by checking the Selected box next to the desired model in the Measures of Fit table in the Model Comparison subtab. Click the blue Save Table button to record this selection.  Use the Delete Row button to remove a model.


###Model output evaluation
Output from the model is saved to the FishSET database in three tables. These tables are saved based on the project name, table phrase, and the date the model was run in YYMD format. The model output tables all contain the phrase *modelout* and the error output tables all contain *ldglobalcheck*.

```{r pressure, echo=FALSE, fig.cap="Example of interactive table", out.width = '1%'}
knitr::include_graphics('C:/Users/melanie.harsch/Pictures/Screenshots/ModelOutTable.png')
```

The first table contains the initial global log likelihood, initial log likelihood for alternative choices, and starting parameters. Use these for assessing the cause of model errors. The second table contains information on the model output, such as convergence, standard errors, and the inverse Hessian matrix. The model comparison or measure of fit table contains AIC, AIC~c~, BIC, Pseudo R^2^. 

<pre> Purpose	                    Function	            Table Name  
Model Error	                globalcheck_view(x)  	<em>project</em>ldglobalcheck<em>YYMD</em>  
Model Output	                model_out_view(x)    	<em>project</em>modelout<em>YYMD</em>  
Model Comparison Metrics	model_fit(x)	        <em>project</em></pre>
