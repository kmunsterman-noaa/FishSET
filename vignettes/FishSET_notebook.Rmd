---
editor_options:
  chunk_output_type: inline
runtime: shiny
output: 
    html_document: default
 #   word_document: default

---
<!-- pdf_document: inst/doc -->


---
title: "FishSET R Package Example"
output: rmarkdown::html_vignette
html_notebook:toc: yes
---
```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = '../') 
# Or use multiple `../` if needed; 
# One `../` means go one level up towards the root,
# here, moving from `scripts` folder to the root `my_project`
```

This tutorial uses [R Markdown](http://rmarkdown.rstudio.com) Notebook to demonstrate the FishSET package. We recommend running FishSET in a Notebook environment to store results and plots. This tutorial is meant to provide an overview of FishSET functionality. For more information on FishSET and the FishSET functions, please read the package documentation and the vignette. A more extensive help document is in development. 

## Installing
Devtools is currently required to install and build FishSET. It will need to be installed and loaded before FishSET can be installed.
We recommend using the following lines to install FishSET.

```{r echo=TRUE}
#    install.packages("devtools") 
#    library(devtools)
#	 install("PATH/TO/Directory/Containing/FishSET")

library(FishSET)
```

When the FishSET package is loaded for the first time, a folder is created in the working directory called *Logs*. All FishSET function calls are saved in dated log files. These log files are useful for documenting which functions are run and the parameter choices. They are also useful for rerunning analyses with updated data. Note that new log files will be saved each day FishSET functions are run however the list of saved functions to be logged will not reset between days if the FishSET package is not closed between days. To reset the list of saved function calls run
```{r echo=TRUE, warning=FALSE}
FishSET:::log_reset()
```

When FishSET is loaded, an RSQLite databased called `fishset_db` is also created in the working directory. All data tables generated using FishSET functions are stored in this database. Data tables are saved as both raw and working tables. To view the tables in the database type
```{r echo=TRUE}
FishSET:::tables_database()
```

The database will be empty if this is the first time you have used FishSET.

##Loading Data

This tutorial uses simulated data. The data is stored in the FishSET R package data folder. Use the *read_dat* function to read in the data. The *read_dat* function reads in several data formats including csv, matlab, and shape. Read the function documentation for more information.
```{r import-data, echo=TRUE}
#Main data 
ExpData <- FishSET:::read_dat('./data/ExpData.RData', data.type = 'R')
head(ExpData)
#Port data
port <- FishSET:::read_dat('./data/port.RData', data.type = 'R')
```


FishSET requires a primary data file that contains the main data for the model, such as haul locations and total catch. Port data, containing the latitude and longitude of ports should also be included. To load the primary data use *load_maindata*. In this example, we set the parameters `compare` to FALSE and `y` to NULL as there is no previous version of the data compare against. 

```{r load-data, echo=TRUE}
#Load main data into fishset_db database
FishSET:::load_maindata(ExpData, over_write = TRUE, project= 'pcod', compare = FALSE, y = NULL)
#Load port data into fishset_db database
FishSET:::load_port(port, port_name='PORT', over_write = TRUE, project = 'pcod', compare = FALSE, y = NULL)
```

Now if we look at the fishset_db database there should be six data tables, raw and working copies of the main data table and an information table that was created by the *load_maindata* function and raw and working copies of the port data created by the *load_port* function.

```{r echo=TRUE}
FishSET:::tables_database()
```

Other data can be loaded into the fishset_db database using *load_aux* and *load_grid*.

The data set is very large with many variables that may be redundant. To subset the data set to only variables that are required for analysis and modeling, use `select_vars` function. To add variables back into the data set at a later date use `add_vars`.
```{r echo=TRUE}
select_vars('pcodMainDataTable', 'pcod')
```

## Checking and cleaning data
Functions can call data tables from the fishset_db database or from the global environment. The first line of code below calls data from the database. This is the preferred method. The second line of code calls data from the global environment.

```{r echo=TRUE}
#Check for common data quality issues
FishSET:::data_check('pcodMainDataTable', 'OFFICIAL_TOTAL_CATCH', 'pcodMainDataTableInfo')
```

The data parser functions (*load_maindata*, *load_port*, *load_aux*, *load_gridd*) call the *data_verification* function. This function checks that each observation is a unique occurrence, that variable names are unique, and that no empty variables exist. The data will not be saved to the fishset_db database if any of these checks fail. The data should also be checked for presence of NAs, NaNs, outliers, and the distribution of location points. The *data_check* function runs these tests. The output states that NAs are present in the data. We can remove those using *na_filter*.

```{r echo=TRUE}
pcodMainDataTable <- FishSET:::na_filter('pcodMainDataTable', c('DEPLOY_LATITUDE','DEPLOY_LONGITUDE'), replace = F, remove = T)
```

The plot raw data, distribution of the data, and Q-Q plot indicate that there may be some extreme data in the upper catch values. We can evaluate for the potential existence of outliers further using the *outlier_plot* function and specifying the parameters for including data.

```{r echo=TRUE}
FishSET:::outlier_plot('pcodMainDataTable', 'OFFICIAL_TOTAL_CATCH', dat.remove='5_95_quant', x.dist='lognormal')
```

In this example, the data appear to better fit a log-normal distribution than a normal distribution. However, removing points outside the 5 to 95 percent quantiles removes more than the extreme upper values and does not result in a better fit. The plot output in this example does not provide evidence that outliers should be removed.

The output from the *data_check* function call also returned a map with haul locations. The plotted haul locations appear to be in the correct location but some occur over land. Points that occur over land or outside zone areas will not be assigned to zones and will not be included in the model. 

```{r echo=FALSE, fig.env='figure', message=FALSE}
map2 <- FishSET:::read_dat('inst/extdata/nmfs_manage_simple.json', 'shape')
temp <- suppressWarnings(FishSET:::assignment_column(pcodMainDataTable, map2, TRUE, 'DEPLOY_LONGITUDE','DEPLOY_LATITUDE', lon.grid='', lat.grid='', cat='NMFS_AREA', closest.pt = FALSE))
graphics::par(mfrow = c(1, 2), mar=c(0,0,0,0), oma=c(0,0,0,0))

maps::map('world', ylim=c(48, 74), xlim=c(-180, -130.2))
plot(map2, add=TRUE)
points(as.numeric(as.character(temp[which(is.na(temp$ZoneID)==TRUE),'DEPLOY_LONGITUDE'])), 
       as.numeric(as.character(temp[which(is.na(temp$ZoneID)==TRUE),'DEPLOY_LATITUDE'])), col='red', pch=19)


maps::map('world', ylim=c(min(temp[,'DEPLOY_LATITUDE'], na.rm=TRUE), max(temp[,'DEPLOY_LATITUDE'], na.rm=TRUE)), xlim=c(min(temp[,'DEPLOY_LONGITUDE'], na.rm=TRUE), max(temp[,'DEPLOY_LONGITUDE'], na.rm=TRUE)))
plot(map2, add=TRUE)
pts <- sample(which(is.na(temp$ZoneID)==FALSE), 100)
points(as.numeric(as.character(temp[pts,'DEPLOY_LONGITUDE'])), 
       as.numeric(as.character(temp[pts, 'DEPLOY_LATITUDE'])), col='red', pch=19)

```
The plot to the left shows points that were not assigned to a NMFS area. These points all fall on land or outside the NMFS areas. The plot on the right shows the points which were assigned to a NMFS area.

## Data analysis
This section demonstrates how to modify existing variables and create new variables from existing ones. See the vignette for a complete list of data creation functions.

### Create CPUE variable.
```{r echo=TRUE}
#Make sure date varibles are in the correct format
pcodMainDataTable$ENDDATE <- FishSET:::temporal_mod(pcodMainDataTable, 'DEPLOYMENT_DATE', define.format='%Y-%m-%d')
#Calculate duration as a measure of fishing effort
pcodMainDataTable$duration <- FishSET:::create_duration(pcodMainDataTable, 'DATESTART', 'ENDDATE',  units = "hour")
#Calculate cpue using catch and duration
pcodMainDataTable$cpue <- FishSET:::cpue(pcodMainDataTable, 'OFFICIAL_TOTAL_CATCH', 'duration')
```

### Collapse data from haul to trip
```{r echo=TRUE}
### Collapse data from Haul to Trip
pcodMainDataTable <- FishSET:::haul_to_trip(pcodMainDataTable, 'pcodMainDataTableInfo',fun.time = min, fun.numeric = mean, 'DEPLOYMENT_DATE')
```

### Save and check data before moving on to modeling
If variables have been created or modified, the data set should be checked one more time before moving on to the modeling functions. This ensures that the data is compatible with the modeling functions. In addition, the modified data set will be saved to the fishset_db database.

```{r echo=TRUE} 
FishSET:::heck_model_data(pcodMainDataTable, 'pcodMainDataTableInfo', uniqueID='rowID', save.file = TRUE)
```

The output from the data check function indicates that NAs are present in the data. We need to remove these and then check the data again.

```{r echo=TRUE}
pcodMainDataTable <- FishSET:::na_filter(pcodMainDataTable, c('DEPLOYMENT_DATE','DATESTART', 'ENDDATE', 'cpue'), replace = F, remove = T)
FishSET:::check_model_data(pcodMainDataTable, 'pcodMainDataTableInfo', uniqueID='rowID', save.file = TRUE)
```

## Spatial functions
```{r KernelDensityPlot, echo=FALSE, fig.cap="", out.width = '1%', warning=FALSE}
#map_kernel('gradient', pcodMainDataTable[,c('DEPLOY_LATITUDE', 'DEPLOY_LONGITUDE')], group=NULL, minmax=NULL)
```

```{r echo=F, warning=F}
# This function returns the lat/long of the haul midpoint.
# The example data does not have lat and long for both start and end points of the haul so we cannot calculate it in this example.
#pcodMainDataTable$haulmid <- create_mid_haul(pcodMainDataTable, c('DEPLOY_LATITUDE', 'DEPLOY_LONGITUDE'), end='')
# Plot historgram of lat/long split by grouping variables
#spatial_hist(pcodMainDataTable, 'GEAR_TYPE')
# Spatial summary statistics plot
FishSET:::spatial_summary(pcodMainDataTable, stat.var='mean', variable='OFFICIAL_TOTAL_CATCH', map2, '', '', 'DEPLOY_LONGITUDE', 'DEPLOY_LATITUDE', 'NMFS_AREA')
```

```{r}
#head(create_dist_between(pcodMainDataTable,'DISEMBARKED_PORT','EMBARKED_PORT', units='meters'))
```

```{r, echo=FALSE}
sliderInput("bins", "Number of bins:", min = 1, max = 50, value = 30)
plotOutput("distPlot")
```

```{r, context="server"}
output$distPlot <- renderPlot({
  x <- faithful[, 2]  # Old Faithful Geyser data
  bins <- seq(min(x), max(x), length.out = input$bins + 1)
  hist(x, breaks = bins, col = 'darkgray', border = 'white')
})
```
Additional spatial functions that cannot be run with this dataset:

  create_mid_haul  Calculate midpoint of a haul
  This function cannot be run because the example dataset 

## Modeling functions

Need shape file for assigning fishing area centroids and assigning fishing occurrences to fishing areas.
```{r echo=TRUE, warning=FALSE, message=F}
map2 <- FishSET:::read_dat('inst/extdata/nmfs_manage_simple.json', 'shape')
```

###CREATE MODEL DESIGN FUNCTIONS
The following functions creates a list containing information on how alternative fishing choices should be defined *create_alternative_choice*, calculate the expectation of catch for alternative choices *create_expectations*, and the model design matrix *make_model_design*. The model design matrix is a list containing actual zonal catch, actual zonal choice, the distance matrix (distance from starting point to alternative choice), price data (if needed), and other data such as independent variables and interaction terms. The output from these functions is saved to the fishset_db database. See package documentation for further information on the parameters for these functions.

Use the tembs_obs_table to check for sparsity. Zones with sparse data can be filterd from the data by setting a minimum haul value (min.haul parameter) in the create_alternative_choice function.
```{r echo=TRUE}
FishSET:::temp_obs_table(pcodMainDataTable, map2, "DATE_FISHING_BEGAN", lon.grid='', lat.grid='', lon.dat='DEPLOY_LONGITUDE', lat.dat='DEPLOY_LATITUDE', cat='NMFS_AREA')
```
**!!!->>> ADD MORE TEXT HERE ON OUTPUT ONCE DATA HAS BEEN REDONE <<<<-!!!!**

```{r model-design-file, echo=TRUE, warning=FALSE}
FishSET:::create_alternative_choice('pcodMainDataTable', map2, case = "Centroid", min.haul = 200, haul.trip = "Trip", alt_var = 'centroid',  occasion = 'centroid', 'DEPLOY_LONGITUDE', 'DEPLOY_LATITUDE', lon.grid='', lat.grid='', cat='NMFS_AREA', use.grid = FALSE, hull.polygon =TRUE, remove.na = T, closest.pt = FALSE, griddedDat = NULL, weight.var = NULL, project = 'pcod')

FishSET:::create_expectations('pcodMainDataTable', 'pcod', map2, catch = 'OFFICIAL_TOTAL_CATCH', temporal = "daily", temp.var = NULL, calc.method = "standardAverage", lag.method = "simple", empty.catch = NULL, empty.expectation = NULL, temp.window = 1, temp.lag = 1, dummy.exp = FALSE, defineGroup = NULL)

FishSET:::make_model_design('pcodMainDataTable', catchID = "OFFICIAL_TOTAL_CATCH", alternativeMatrix = "loaded data", 'DEPLOY_LONGITUDE', 'DEPLOY_LATITUDE', indeVarsForModel = "", gridVariablesInclude = "", priceCol = NULL, vesselID = NULL, project = 'pcod')
```

At this point, several tables should exist in the fishset_db database, including a model design file.

```{r}
FishSET:::tables_database()
```

The discrete choice model can be run after the model design folder is created. The function calls the working model design file from the database. Data (catch, choice, distance matrix, expected catch, independent variables, interaction terms, grid varying variables) for the matrix is contained in the model design file. The initial parameters, optimization options, likelihood function, and optimization method need to be defined. Model measures of fit are stored in a table and saved to the fishset_db database. Output from models is added to the table after each run of *discretefish_subroutine*. Use the `mod.name` parameter to distinguish between model runs.

```{r discrete-choice-model, echo=TRUE}
#RUN MODEL FUNCTIONS
#Average catch example
#discretefish_subroutine("pcod", initparams=c(2.5, -.1, 1, -.2, 1, 1, 1, .1), optimOpt=c(1000,1.00e-08,1,1), func=logit_avgcat, methodname="BFGS", mod.name='pcod_avg_cat', select.model=FALSE)
#conditional logit example
#discretefish_subroutine("pcod", initparams=c(2.5, -.1), optimOpt=c(1000,1.00e-08,1,1), func=logit_c, methodname="BFGS", mod.name='pcod_logitParamSet1', select.model=FALSE)
results <- model_out_view("pcodmodelout20190604")
print(str(results))
print(results[[1]]$MCM)
errors <- FishSET:::globalcheck_view("pcodldglobalcheck20190604")
```

```{r, echo=FALSE}
  library(shiny)
  library(shinyjs) #resettable
  dat <- pcodMainDataTable
  runApp(list(
    model_table <- data.frame('mod_name'='', 'likelihood'='', 'alternatives'=''),
    ui = fluidPage(
      useShinyjs(),


      sidebarLayout(
        sidebarPanel(
          tags$br(),tags$br(),
          actionButton("addModel", "Save model and add new model", style="color: #fff; background-color: #337ab7; border-color: #800000;"),
          tags$br(),tags$br(),
          actionButton("submit", "Run model", style="color: #fff; background-color: #6da363; border-color: #800000;"),
          tags$br(),tags$br(),
          tags$button(
            id = 'close',
            type = "button",
            style="color: #fff; background-color: #FF6347; border-color: #800000;",
            class = "btn action-button",
            onclick = "setTimeout(function(){window.close();},500);",  # close browser
            "Close window"
          )),
        mainPanel(
            div(id = "form",
          h3('Alternative choice matrix parameters'),
          selectInput("alternatives", label = "Create alternative choice matrix from",
                      choices = list("Loaded data" = 'loadedData', "Grid data" = "griddedData"),
                      selected = 'loadedData'),
           conditionalPanel(
             condition="input.alternatives=='loadedData'",
            selectInput('lat', 'Occurrence latitude', choices=colnames(dat[,grep('lat', colnames(dat), ignore.case=TRUE)])),
            selectInput('lon', 'Occurrence longitude', choices=colnames(dat[,grep('lon', colnames(dat), ignore.case=TRUE)]))
            ),
          h4('Select variables to include in model'),
          uiOutput('indvariables'),
          uiOutput('gridvariables'),
          selectInput('catch','Variable containing catch data', choices=colnames(dat[,grep('haul|mt|lb|metric|pounds|catch', colnames(dat), ignore.case=TRUE)])),
          h3('Model parameters'),
          selectInput("model", label = "Likelihood function",
                      choices = list("Conditional logit" = 'logit_c', "Average catch" = "logit_avgcat", 'EPM normal'='epm_normal',
                                     'EPM lognormal'='epm_lognormal', 'EPM Weibull'='epm_weibull'),
                      selected = 'logit_c'),
          
          fluidRow(
               h4("Optimization options"),
                   splitLayout(cellWidths = c("22%", "22%", "22%", "22%"),
                        numericInput("mIter", "max iterations", value = 100000),
                        numericInput("relTolX", "tolerance of x", value = 0.00000001),
                        numericInput("reportfreq", "report frequency", value = 1),
                        numericInput("detailreport", "detailed report", value = 1)
               )
          ),
          fluidRow(
               h4('Initial parameters'),
               uiOutput("Inits")
               #uiOutput("ui1")
          ),
          conditionalPanel(
            condition="input.model=='epm_normal' || input.model=='epm_lognormal' || input.model=='epm_weibull'",
             checkboxInput('lockk', 'Location-specific catch parameter', value=FALSE),
             textInput('price', 'Price variable', value='NULL')
          ),
          
            dataTableOutput('table')
            )
          

          
        ))),
## BEGIN SERVER FILE ##
    server = function(input, output, session) {
      
      
      
      # helper function for making checkbox
      #names <- c('one','two', 'three')
      inline = function (x) {
        tags$div(style="display:inline-block;", x)
      }
      
      # Data needed
        ## Alternative choices
        if (!exists("Alt")) {
          if (!exists('AltMatrixName')) {
            fishset_db <- DBI::dbConnect(RSQLite::SQLite(), "fishset_db.sqlite")
            Alt <- unserialize(DBI::dbGetQuery(fishset_db, paste0("SELECT AlternativeMatrix FROM ", project, "altmatrix LIMIT 1"))$AlternativeMatrix[[1]])
            DBI::dbDisconnect(fishset_db)
            if (!exists("Alt")) {
              stop("Alternative Choice Matrix does not exist. Please run the createAlternativeChoice() function.")
            }
          }
        }
      choice <- Alt[["choice"]]
      alt <- dim(table(choice))
      #Main Data frame
      fishset_db <- DBI::dbConnect(RSQLite::SQLite(), "fishset_db.sqlite")
      if(is.character(dat)==TRUE){
        if(is.null(dat)==TRUE | table_exists(dat)==FALSE){
          print(DBI::dbListTables(fishset_db))
          stop(paste(dat, 'not defined or does not exist. Consider using one of the tables listed above that exist in the database.'))
        } else {
          dat <- table_view(dat)
        }
      } else {
        dat <- dat  
      }
      
         dat <- dat
         drop <- grep('date|port|processor|gear|target|lon|lat|permit|ifq', colnames(dat), ignore.case=TRUE)
         
       
         
         output$indvariables <- renderUI ({
              intvariables <- c('none', colnames(dat[,-drop]))
              selectInput("indeVarsForModel", label = "Independent variables for model", multiple=TRUE,
                          choices = intvariables,
                          selected = 'none')
         })
         
            
         output$gridvariables <- renderUI ({
            if(FishSET:::is_empty(gridVariablesInclude)) {
              selectInput("gridVariablesInclude", label = "Grid varying variables for model", multiple=TRUE,
                          choices = 'none',
                          selected = 'none')
            } else {
              selectInput("gridVariablesInclude", label = "Grid varying variables for model", multiple=TRUE,
                          choices = c('none', names(gridVariablesInclude)),
                          selected = names(gridVariablesInclude))
            }
         })
         
         output$Inits <- renderUI({
              gridNum <- as.integer(as.factor(length(input$gridVariablesInclude)))
              intNum <- as.integer(length(input$indeVarsForModel))
              if(input$model == 'logit_c'){
                   numInits <- gridNum+intNum
              } else if(input$model == 'logit_avgcat') {
                   numInits <- gridNum*(alt-1)+intNum
              } else {
                   if(input$lockk=='TRUE'){
                     numInits <- gridNum*alt+intNum+alt+1  
                   } else {
                   numInits <- gridNum*alt+intNum+1+1
                   }
              }
              i = 1:numInits
              numwidth <- rep(1/numInits*100, numInits)
              numwidth <- paste("'",as.character(numwidth),"%'",collapse=", ",sep="")
              UI <- paste0("splitLayout(",
                           "cellWidths = c(",numwidth,")",",",
                           paste0("textInput(", 
                                  "'int", i, "', ",
                                  paste0("''"), ",",
                                  value=1, 
                                  #"width='",1/numInits*100,"%'",#50px'",
                                  ")",
                                  collapse = ", "),
                           ")")
              eval(parse(text = UI))
         }) 

         #mod.table <- data.frame('mod_name'='mod1', 'likelihood'=input$model, 'alternatives'=input$alternatives)#, 'independent vars'=input$indeVarsForModel,
                                # 'gridvariables'=input$gridVariablesInclude)
         # Save model and add new model shiny
         #observe({
         #  if (input$addModel > 0) print('Save model, reset parameters')
         #  output$table <- renderDataTable(dat[1:3,1:3])
           #make_model_design()
         #})
         counter <- reactiveValues(countervalue = 0) # Defining & initializing the reactiveValues object
         model_table <- reactiveVal(model_table)
         
         observeEvent(input$addModel, {
           showNotification("Selected model parameters saved.", type='message', duration=10)
           #make_model_design(dat, input$catch, input$alternatives, input$lon, input$lat, project, input$indeVarsForModel, input$gridVariablesInclude, input$price)
             counter$countervalue <- counter$countervalue + 1   
           #  
             t = rbind(data.frame('mod_name'=paste0('mod',counter$countervalue), 'likelihood'=input$model, 'alternatives'=input$alternatives), model_table())
             model_table(t)
           
           reset("form")
         })
 
         output$table <- renderDataTable({
           model_table()
         })
         # Save model and add new model shiny
         observe({
           if (input$submit > 0) print('call model design function, call discrete_subroutine file')
         })
         
      # stop shiny
      observe({
        if (input$close > 0) stopApp()
      })

}
  ))

```